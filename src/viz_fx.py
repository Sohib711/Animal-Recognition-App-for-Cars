import pickle
import random
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.figure_factory as ff
import tensorflow as tf
import visualkeras

from pandas import DataFrame
from PIL import ImageFont
from collections import defaultdict
from typing import Any, Optional
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers

from src.constants import LABELS, SEED, BATCH_SIZE
from src.utils import calculate_mean_std

def images_viz(rows: int, cols: int, set_length: int, X: np.ndarray, y: np.ndarray, set: str = 'train') -> None:
    """
    Visualize a grid of images from the dataset.

    Args:
        rows (int): Number of rows in the grid.
        cols (int): Number of columns in the grid.
        set_length (int): Total number of images in the dataset.
        X (np.ndarray): Dataset of images (assumed as 4D array: (num_samples, height, width, channels)).
        y (np.ndarray): Labels corresponding to the dataset images.
        set (str): Specifies whether the images are from the 'train' or 'test' set. Default is 'train'.

    Returns:
        None: Displays a grid of images with titles.
    """
    
    fig, axes = plt.subplots(rows, cols, figsize=(20, 20))
    fig.suptitle(f"X {set} images", y=1.03, fontsize=25)
    
    for i in np.arange(0, rows * cols):
        axes_flat = axes.flatten()  
        try:
            img_index = np.random.randint(0, set_length) 
            img = X[img_index]  
            label = int(y[img_index]) 
            
            axes_flat[i].imshow(img)
            axes_flat[i].set_title(LABELS[label], fontsize=15)
            axes_flat[i].axis('off') 
            
        except IndexError:
            print(f"Index {img_index} is out of bounds for dataset of length {set_length}. Skipping this image.")
    
    plt.tight_layout()
    plt.show()


def class_distribution(y_train: np.ndarray, y_test: np.ndarray) -> None:
    """
    Visualize the class distribution for both the training and test sets.

    Args:
        y_train (np.ndarray): Labels for the training set.
        y_test (np.ndarray): Labels for the test set.

    Returns:
        None: Displays a grouped bar chart comparing the distribution of labels 
              in the training and test sets.
    """
    
    train_label_counts = np.bincount(y_train)
    test_label_counts = np.bincount(y_test)

    label_names = [LABELS[i] for i in np.arange(0, 10)]
    
    fig = go.Figure()

    fig.add_trace(
        go.Bar(
            x=train_label_counts,
            y=label_names,
            name='Training set',
            marker_color='coral',
            orientation='h'
        )
    )

    fig.add_trace(
        go.Bar(
            x=test_label_counts,
            y=label_names,
            name='Test set',
            marker_color='blue',
            orientation='h'
        )
    )

    fig.update_layout(
        title="Labels distribution for Training and Test set",
        xaxis=dict(
            title='Count'
        ),
        yaxis=dict(
            title='Labels'    
        ),
        barmode='group'
    )

    fig.show()


def histogram_distributions(instance: int, X: np.ndarray) -> None:
    """
    Visualize the histogram distributions for all pixels and individual RGB channels of a single image.

    Args:
        instance (int): The index of the image in the dataset to visualize.
        X (np.ndarray): A dataset of images, assumed to be in the shape (num_samples, height, width, channels).

    Returns:
        None: Displays two histograms, one for all pixels combined and one for the RGB channels separately.
    """
    
    img = X[instance]

    red_channel = img[:, :, 0].flatten()
    green_channel = img[:, :, 1].flatten()
    blue_channel = img[:, :, 2].flatten()
    all_pixels = img.flatten()

    fig1 = ff.create_distplot(
        [all_pixels],
        group_labels=['All Pixels'],
        show_hist=True,
        show_rug=True,
        colors=['grey']
    )

    fig2 = ff.create_distplot(
        [red_channel, green_channel, blue_channel], 
        group_labels=['Red', 'Green', 'Blue'], 
        show_hist=True, 
        show_rug=True,
        colors=['red', 'green', 'blue']
    )

    fig1.update_layout(
        title='All Combined Pixels Distribution', 
        xaxis_title='Pixel Intensity', 
        yaxis_title='Probability Density'
    )
    
    fig2.update_layout(
        title='Channels (R, G, B) Distributions', 
        xaxis_title='Pixel Intensity', 
        yaxis_title='Probability Density'
    )

    fig1.show()
    fig2.show()


def viz_images_generator(data_gen: ImageDataGenerator, X: np.ndarray) -> None:
    """
    Visualize augmented images generated by an ImageDataGenerator.

    Args:
        data_gen (ImageDataGenerator): The data generator used to augment the images.
        X (np.ndarray): A batch of images to augment and visualize.

    Returns:
        None: Displays a 4x4 grid of augmented images.
    """
    
    images = data_gen.flow(X, batch_size=1)
    plt.figure(figsize=(16, 16))
    
    for i in range(1, 17):
        plt.subplot(4, 4, i)
        batch = next(images)
        image = batch[0].astype("uint8")  # Convert float image back to uint8 for visualization
        plt.imshow(image)
        plt.axis("off")
    
    plt.show()



def scatter_plot_metrics(file_name: str) -> None:
    """
    Plot chosen metrics from a training history file.

    Args:
        file_name (str): The name of the history file containing training metrics.

    Returns:
        None: Displays a scatter plot of the training and validation metrics.
    """
    
    with open("History_models/" + file_name, 'rb') as history_file:
        history = pickle.load(history_file)

    epochs = list(range(1, len(next(iter(history.values()))) + 1))

    fig = go.Figure()

    dropdown_buttons = []
    metric_pairs = {}

    for key in history.keys():
        if key.startswith('val_'):
            metric_name = key[4:] 
            if metric_name in history:
                metric_pairs[metric_name] = (history[metric_name], history[key])
    
    for i, (metric, (train_data, val_data)) in enumerate(metric_pairs.items()):
        train_mean, train_std = calculate_mean_std(train_data)
        val_mean, val_std = calculate_mean_std(val_data)

        fig.add_trace(go.Scatter(
            x=epochs, y=train_data, mode='lines+markers', visible=(i == 0),
            name=f'Train {metric.capitalize()} (Mean: {train_mean:.2f}, Std: {train_std:.2f})'
        ))
        fig.add_trace(go.Scatter(
            x=epochs, y=val_data, mode='lines+markers', visible=(i == 0),
            name=f'Val {metric.capitalize()} (Mean: {val_mean:.2f}, Std: {val_std:.2f})'
        ))

        dropdown_buttons.append({
            'label': metric.capitalize(),
            'method': 'update',
            'args': [
                {'visible': [False] * len(metric_pairs) * 2},  
                {'title': f'{metric.capitalize()}'}
            ]
        })
        dropdown_buttons[-1]['args'][0]['visible'][i * 2] = True  
        dropdown_buttons[-1]['args'][0]['visible'][i * 2 + 1] = True  

    fig.update_layout(
        title='Model Performance per Epoch',
        xaxis_title='Epoch',
        yaxis_title='Metric Value',
        updatemenus=[{
            'buttons': dropdown_buttons,
            'direction': 'down',
            'showactive': True,
        }],
        legend_title="Legend"
    )

    fig.show()


def plot_model_history(history: dict) -> plt.Figure:
    """
    Plot the training history of a model, including loss, accuracy, and precision.

    Args:
        history (dict): A dictionary containing the training metrics (loss, accuracy, etc.) for each epoch.

    Returns:
        plt.Figure: The figure containing the plots for the training history.
    """
    
    fig = plt.figure(figsize=(12, 16))

    # Loss
    mean_loss, std_loss = calculate_mean_std(history['loss'])
    mean_val_loss, std_val_loss = calculate_mean_std(history['val_loss'])
    plt.subplot(4, 2, 1)
    plt.plot(history['loss'], label=f'Loss (mean: {mean_loss:.3f} ± {std_loss:.3f})')
    plt.plot(history['val_loss'], label=f'Val Loss (mean: {mean_val_loss:.3f} ± {std_val_loss:.3f})')
    plt.title('Loss Metric per Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Accuracy
    mean_acc, std_acc = calculate_mean_std(history['accuracy'])
    mean_val_acc, std_val_acc = calculate_mean_std(history['val_accuracy'])
    plt.subplot(4, 2, 2)
    plt.plot(history['accuracy'], label=f'Accuracy (mean: {mean_acc:.3f} ± {std_acc:.3f})')
    plt.plot(history['val_accuracy'], label=f'Val Accuracy (mean: {mean_val_acc:.3f} ± {std_val_acc:.3f})')
    plt.title('Accuracy Metric per Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Precision
    mean_prec, std_prec = calculate_mean_std(history['precision'])
    mean_val_prec, std_val_prec = calculate_mean_std(history['val_precision'])
    plt.subplot(4, 2, 3)
    plt.plot(history['precision'], label=f'Precision (mean: {mean_prec:.3f} ± {std_prec:.3f})')
    plt.plot(history['val_precision'], label=f'Val Precision (mean: {mean_val_prec:.3f} ± {std_val_prec:.3f})')
    plt.title('Precision Metric per Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Precision')
    plt.legend()

    plt.tight_layout()
    return fig


def bar_plot_metric_performances(df_metric: DataFrame) -> go.Figure:
    """
    Create a bar plot to compare model performances based on specified metrics.

    Args:
        df_metric (DataFrame): A DataFrame containing model names and their performance metrics.

    Returns:
        go.Figure: A Plotly figure object containing the bar plot.
    """
    
    metrics = ['accuracy', 'loss', 'precision']
    dropdown_buttons = []

    fig = go.Figure()

    for i, metric in enumerate(metrics):
        # Training metrics
        fig.add_trace(go.Bar(
            x=df_metric['Model'],
            y=df_metric[f'{metric} Mean'].round(3),
            error_y=dict(type='data', array=df_metric[f'{metric} Std'].round(3), visible=True),
            name=f'Train {metric.capitalize()}',
            marker_color='green',
            visible=(i == 0)
        ))

        # Validation metrics
        fig.add_trace(go.Bar(
            x=df_metric['Model'],
            y=df_metric[f'val_{metric} Mean'].round(3),
            error_y=dict(type='data', array=df_metric[f'val_{metric} Std'].round(3), visible=True),
            name=f'Validation {metric.capitalize()}',
            marker_color='coral',
            visible=(i == 0)
        ))

        # Dropdown button setup
        dropdown_buttons.append({
            'label': metric.capitalize(),
            'method': 'update',
            'args': [
                {'visible': [False] * len(metrics) * 2},
                {'title': f'{metric.capitalize()} Comparison'}
            ]
        })
        dropdown_buttons[-1]['args'][0]['visible'][i * 2] = True   
        dropdown_buttons[-1]['args'][0]['visible'][i * 2 + 1] = True  

    fig.update_layout(
        title='Model Comparison: Accuracy, Loss, Precision',
        xaxis_title='Model',
        yaxis_title='Metric Value',
        barmode='group',
        updatemenus=[{
            'buttons': dropdown_buttons,
            'direction': 'down',
            'showactive': True,
        }]
    )

    return fig


def plot_misclassified_images(model: tf.keras.Model, 
                              X_test: np.ndarray, 
                              y_test_binary: np.ndarray, 
                              class_labels: list, 
                              num_images: int = 25) -> None:
    """
    Plot images that were misclassified by the model.

    Args:
        model (tf.keras.Model): The trained Keras model to evaluate.
        X_test (np.ndarray): The test set features.
        y_test_binary (np.ndarray): The binary labels for the test set.
        class_labels (list): The list of class labels.
        num_images (int): The number of misclassified images to display.

    Returns:
        None: Displays a grid of misclassified images with their predicted and true labels.
    """
    
    test_datagen = ImageDataGenerator(rescale=1./255)
    test_generator = test_datagen.flow(
        X_test,
        y_test_binary,
        batch_size=BATCH_SIZE,
        seed=SEED,
        shuffle=False  # Keep shuffle False for evaluation
    )
    
    y_pred_prob = model.predict(test_generator)
    y_pred = np.where(y_pred_prob <= 0.5, 0, 1)
    misclassified_indices = np.where(y_pred.flatten() != test_generator.y.flatten())[0]
    
    if len(misclassified_indices) < num_images:
        print(f"There are only {len(misclassified_indices)} available misclassified images.")
        num_images = len(misclassified_indices)
    
    random_indices = random.sample(list(misclassified_indices), num_images)
    
    # Plot the misclassified images
    plt.figure(figsize=(12, 12))
    for i, idx in enumerate(random_indices):
        plt.subplot(5, 5, i + 1)
        plt.imshow(X_test[idx])
        plt.axis("off")
        predicted_label = class_labels[int(y_pred[idx])]
        true_label = class_labels[int(test_generator.y[idx])]
        plt.title(f"Pred: {predicted_label}\nTrue: {true_label}", fontsize=12)
    
    plt.tight_layout()
    plt.show()


def visualize_model(model: Any, 
                    to_file: Optional[str] = None, 
                    font_path: Optional[str] = None) -> None:
    """
    Visualizes a Keras model in a layered view.

    Args:
        model (Any): The Keras model to visualize.
        to_file (Optional[str]): If provided, saves the visualization to this file path.
        font_path (Optional[str]): Path to a custom font file for labels.
    """
    
    color_map = defaultdict(dict)
    color_map[layers.Conv2D]['fill'] = '#00f5d4'
    color_map[layers.MaxPooling2D]['fill'] = '#8338ec'
    color_map[layers.Dropout]['fill'] = '#03045e'
    color_map[layers.Dense]['fill'] = '#fb5607'
    color_map[layers.Flatten]['fill'] = '#ffbe0b'

    if font_path:
        font = ImageFont.truetype(font_path, 12)
        visualkeras.layered_view(model, legend=True, font=font, color_map=color_map, to_file=to_file)
    else:
        visualkeras.layered_view(model, legend=True, color_map=color_map, to_file=to_file)